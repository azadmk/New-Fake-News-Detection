{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-09T20:29:30.174152Z",
     "iopub.status.busy": "2025-02-09T20:29:30.173815Z",
     "iopub.status.idle": "2025-02-09T20:29:49.394864Z",
     "shell.execute_reply": "2025-02-09T20:29:49.393701Z",
     "shell.execute_reply.started": "2025-02-09T20:29:30.174113Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import string\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:29:49.396772Z",
     "iopub.status.busy": "2025-02-09T20:29:49.396102Z",
     "iopub.status.idle": "2025-02-09T20:29:49.517752Z",
     "shell.execute_reply": "2025-02-09T20:29:49.516732Z",
     "shell.execute_reply.started": "2025-02-09T20:29:49.396741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:29:49.520868Z",
     "iopub.status.busy": "2025-02-09T20:29:49.520578Z",
     "iopub.status.idle": "2025-02-09T20:30:07.430974Z",
     "shell.execute_reply": "2025-02-09T20:30:07.429359Z",
     "shell.execute_reply.started": "2025-02-09T20:29:49.520843Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dse = pd.read_excel('/kaggle/input/kurdishenglish/KDFND_Anlyzed_Cleaned_Filtered_Labeld.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:30:07.433542Z",
     "iopub.status.busy": "2025-02-09T20:30:07.432674Z",
     "iopub.status.idle": "2025-02-09T20:30:07.544921Z",
     "shell.execute_reply": "2025-02-09T20:30:07.543684Z",
     "shell.execute_reply.started": "2025-02-09T20:30:07.433502Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-5b975b974219>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dsk[\"Article\"] = dsk[\"Text_Translate_to_English\"]\n",
      "<ipython-input-4-5b975b974219>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dsk['label'] = dsk['label'].map({'Real': 0, 'Fake': 1})  # Convert labels to 0 and 1\n"
     ]
    }
   ],
   "source": [
    "dsk = dse.dropna(subset=['Text_Translate_to_English'])\n",
    "dsk[\"Article\"] = dsk[\"Text_Translate_to_English\"]\n",
    "dsk['label'] = dsk['label'].map({'Real': 0, 'Fake': 1})  # Convert labels to 0 and 1\n",
    "dsk = dsk[['Article', 'label']].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:30:07.546308Z",
     "iopub.status.busy": "2025-02-09T20:30:07.545980Z",
     "iopub.status.idle": "2025-02-09T20:30:07.594200Z",
     "shell.execute_reply": "2025-02-09T20:30:07.592917Z",
     "shell.execute_reply.started": "2025-02-09T20:30:07.546280Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced class distribution:\n",
      "label\n",
      "1    50210\n",
      "0    50210\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# Assuming 'dsk' is your DataFrame and you have a binary label column called 'label'\n",
    "# Split the dataset into majority and minority classes\n",
    "majority_class = dsk[dsk['label'] == 0]\n",
    "minority_class = dsk[dsk['label'] == 1]\n",
    "\n",
    "# Perform oversampling on the minority class # Sample with replacement  # Match majority size\n",
    "###minority_oversampled = resample(minority_class,replace=True, n_samples=len(majority_class), random_state=42)  # For reproducibility\n",
    "# Perform undersampling on the minority class\n",
    "majority_undersampled = resample(majority_class,replace=True, n_samples=len(minority_class), random_state=42)  # For reproducibility\n",
    "\n",
    "# Combine majority class with the oversampled minority class\n",
    "###dskb = pd.concat([majority_class, minority_oversampled])\n",
    "# Combine majority class with the undersampled minority class\n",
    "dskb = pd.concat([minority_class, majority_undersampled])\n",
    "\n",
    "# Shuffle the dataset\n",
    "dskb = dskb.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"Balanced class distribution:\")\n",
    "print(dskb['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:30:07.595858Z",
     "iopub.status.busy": "2025-02-09T20:30:07.595458Z",
     "iopub.status.idle": "2025-02-09T20:30:08.387342Z",
     "shell.execute_reply": "2025-02-09T20:30:08.385613Z",
     "shell.execute_reply.started": "2025-02-09T20:30:07.595817Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Text Preprocessing\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Keep only letters\n",
    "        text = text.lower().strip()\n",
    "        words = text.split()\n",
    "        #words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words or word in ['not', 'never']]\n",
    "        return ' '.join(words)\n",
    "    return ''\n",
    "\n",
    "dskb['Article'] = dskb['Article'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:30:08.388620Z",
     "iopub.status.busy": "2025-02-09T20:30:08.388141Z",
     "iopub.status.idle": "2025-02-09T20:30:08.444415Z",
     "shell.execute_reply": "2025-02-09T20:30:08.443175Z",
     "shell.execute_reply.started": "2025-02-09T20:30:08.388580Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dskb['label1'] = \"__label__\" + dskb['label'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:30:08.446683Z",
     "iopub.status.busy": "2025-02-09T20:30:08.445671Z",
     "iopub.status.idle": "2025-02-09T20:30:08.528837Z",
     "shell.execute_reply": "2025-02-09T20:30:08.527622Z",
     "shell.execute_reply.started": "2025-02-09T20:30:08.446640Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>label</th>\n",
       "      <th>label1</th>\n",
       "      <th>label_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pieces of artifacts will be handed over to ira...</td>\n",
       "      <td>1</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 pieces of artifacts will be handed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>because of the demonstration no one was arrest...</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__0</td>\n",
       "      <td>__label__0 because of the demonstration no one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the iraqi customs committee has increased its ...</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__0</td>\n",
       "      <td>__label__0 the iraqi customs committee has inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>other american b planes were sent to the gulf</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__0</td>\n",
       "      <td>__label__0 other american b planes were sent t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the minister of education has been building sc...</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__0</td>\n",
       "      <td>__label__0 the minister of education has been ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100415</th>\n",
       "      <td>a yearold man named osama jabbar mohammed a ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 a yearold man named osama jabbar mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100416</th>\n",
       "      <td>nuri maliki the demonstrators we are doing you...</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__0</td>\n",
       "      <td>__label__0 nuri maliki the demonstrators we ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100417</th>\n",
       "      <td>the worlds oil markets have declined and the d...</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__0</td>\n",
       "      <td>__label__0 the worlds oil markets have decline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100418</th>\n",
       "      <td>kurdistan parliament awards a shepherd for yea...</td>\n",
       "      <td>1</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 kurdistan parliament awards a sheph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100419</th>\n",
       "      <td>without the information we have the conflict o...</td>\n",
       "      <td>1</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 without the information we have the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100420 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Article  label      label1  \\\n",
       "0       pieces of artifacts will be handed over to ira...      1  __label__1   \n",
       "1       because of the demonstration no one was arrest...      0  __label__0   \n",
       "2       the iraqi customs committee has increased its ...      0  __label__0   \n",
       "3           other american b planes were sent to the gulf      0  __label__0   \n",
       "4       the minister of education has been building sc...      0  __label__0   \n",
       "...                                                   ...    ...         ...   \n",
       "100415  a yearold man named osama jabbar mohammed a ba...      1  __label__1   \n",
       "100416  nuri maliki the demonstrators we are doing you...      0  __label__0   \n",
       "100417  the worlds oil markets have declined and the d...      0  __label__0   \n",
       "100418  kurdistan parliament awards a shepherd for yea...      1  __label__1   \n",
       "100419  without the information we have the conflict o...      1  __label__1   \n",
       "\n",
       "                                        label_description  \n",
       "0       __label__1 pieces of artifacts will be handed ...  \n",
       "1       __label__0 because of the demonstration no one...  \n",
       "2       __label__0 the iraqi customs committee has inc...  \n",
       "3       __label__0 other american b planes were sent t...  \n",
       "4       __label__0 the minister of education has been ...  \n",
       "...                                                   ...  \n",
       "100415  __label__1 a yearold man named osama jabbar mo...  \n",
       "100416  __label__0 nuri maliki the demonstrators we ar...  \n",
       "100417  __label__0 the worlds oil markets have decline...  \n",
       "100418  __label__1 kurdistan parliament awards a sheph...  \n",
       "100419  __label__1 without the information we have the...  \n",
       "\n",
       "[100420 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dskb['label_description'] = dskb['label1'].astype(str) + \" \" + dskb['Article'].astype(str)\n",
    "\n",
    "dskb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:30:08.530253Z",
     "iopub.status.busy": "2025-02-09T20:30:08.529865Z",
     "iopub.status.idle": "2025-02-09T20:30:08.565994Z",
     "shell.execute_reply": "2025-02-09T20:30:08.564730Z",
     "shell.execute_reply.started": "2025-02-09T20:30:08.530222Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(dskb, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:30:08.567718Z",
     "iopub.status.busy": "2025-02-09T20:30:08.567321Z",
     "iopub.status.idle": "2025-02-09T20:30:09.135512Z",
     "shell.execute_reply": "2025-02-09T20:30:09.134407Z",
     "shell.execute_reply.started": "2025-02-09T20:30:08.567683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"fake_news_train.txt\", columns = ['label_description'], index=False, sep=' ', header=False,\n",
    "    quoting=3, escapechar=' ', mode='w')\n",
    "test.to_csv(\"fake_news_test.txt\", columns = ['label_description'], index=False, sep=' ', header=False,\n",
    "    quoting=3, escapechar=' ', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:30:09.137055Z",
     "iopub.status.busy": "2025-02-09T20:30:09.136623Z",
     "iopub.status.idle": "2025-02-09T20:31:03.765675Z",
     "shell.execute_reply": "2025-02-09T20:31:03.764510Z",
     "shell.execute_reply.started": "2025-02-09T20:30:09.137013Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train FastText Model\n",
    "fasttext_model = fasttext.train_supervised(input=\"fake_news_train.txt\", lr=0.5, epoch=25, wordNgrams=2, dim=300)\n",
    "y_predic = fasttext_model.test(\"fake_news_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:31:03.769004Z",
     "iopub.status.busy": "2025-02-09T20:31:03.768666Z",
     "iopub.status.idle": "2025-02-09T20:31:03.776469Z",
     "shell.execute_reply": "2025-02-09T20:31:03.775020Z",
     "shell.execute_reply.started": "2025-02-09T20:31:03.768976Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Test: 20084\n",
      "Precision: 0.845449\n",
      "Recall: 0.845449\n",
      "F1-Score: 0.845449\n"
     ]
    }
   ],
   "source": [
    "N = y_predic[0]\n",
    "P = y_predic[1]\n",
    "R = y_predic[2]\n",
    "\n",
    "print(f\"No. of Test: {N:}\")\n",
    "print(f\"Precision: {P:.6f}\")\n",
    "print(f\"Recall: {R:.6f}\")\n",
    "\n",
    "print(f\"F1-Score: {2*((P*R)/(P+R)):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:31:03.777910Z",
     "iopub.status.busy": "2025-02-09T20:31:03.777602Z",
     "iopub.status.idle": "2025-02-09T20:31:08.743521Z",
     "shell.execute_reply": "2025-02-09T20:31:08.742312Z",
     "shell.execute_reply.started": "2025-02-09T20:31:03.777881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to get FastText vector safely\n",
    "def fasttext_vector(text):\n",
    "    if isinstance(text, str):  # Ensure text is a string\n",
    "        text = text.replace(\"\\n\", \" \").strip()  # Remove newlines\n",
    "        return fasttext_model.get_sentence_vector(text)\n",
    "    return np.zeros(300)  # Return zero vector for empty/non-string values\n",
    "\n",
    "# Apply FastText vectors to dataset\n",
    "X_fasttext = np.array([fasttext_vector(text) for text in dskb['Article']])\n",
    "# Function to get FastText vector\n",
    "y = np.array(dskb['label'])\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fasttext, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:31:08.745186Z",
     "iopub.status.busy": "2025-02-09T20:31:08.744827Z",
     "iopub.status.idle": "2025-02-09T20:31:14.489966Z",
     "shell.execute_reply": "2025-02-09T20:31:14.488682Z",
     "shell.execute_reply.started": "2025-02-09T20:31:08.745155Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "max_words = 10000\n",
    "max_len = 200\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(dskb['Article'])\n",
    "X_sequences = tokenizer.texts_to_sequences(dskb['Article'])\n",
    "X_padded = pad_sequences(X_sequences, maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:31:14.491532Z",
     "iopub.status.busy": "2025-02-09T20:31:14.491040Z",
     "iopub.status.idle": "2025-02-09T20:31:14.586649Z",
     "shell.execute_reply": "2025-02-09T20:31:14.585326Z",
     "shell.execute_reply.started": "2025-02-09T20:31:14.491498Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Embedding Matrix from FastText\n",
    "embedding_matrix = np.zeros((max_words, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_matrix[i] = fasttext_model.get_word_vector(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T23:19:01.434534Z",
     "iopub.status.busy": "2025-01-30T23:19:01.434033Z",
     "iopub.status.idle": "2025-01-30T23:19:01.517310Z",
     "shell.execute_reply": "2025-01-30T23:19:01.516117Z",
     "shell.execute_reply.started": "2025-01-30T23:19:01.434495Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=300, weights=[embedding_matrix], input_length=max_len, trainable=True),\n",
    "    Bidirectional(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    LSTM(32, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T23:19:05.631536Z",
     "iopub.status.busy": "2025-01-30T23:19:05.631132Z",
     "iopub.status.idle": "2025-01-31T00:09:19.377784Z",
     "shell.execute_reply": "2025-01-31T00:09:19.376334Z",
     "shell.execute_reply.started": "2025-01-30T23:19:05.631503Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 443ms/step - accuracy: 0.7967 - loss: 0.4611 - val_accuracy: 0.8265 - val_loss: 0.3956\n",
      "Epoch 2/5\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 440ms/step - accuracy: 0.8441 - loss: 0.3738 - val_accuracy: 0.8305 - val_loss: 0.3948\n",
      "Epoch 3/5\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 438ms/step - accuracy: 0.8699 - loss: 0.3171 - val_accuracy: 0.8387 - val_loss: 0.3881\n",
      "Epoch 4/5\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 439ms/step - accuracy: 0.8912 - loss: 0.2688 - val_accuracy: 0.8413 - val_loss: 0.3999\n",
      "Epoch 5/5\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 438ms/step - accuracy: 0.9073 - loss: 0.2305 - val_accuracy: 0.8430 - val_loss: 0.4293\n",
      "\u001b[1m3139/3139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 78ms/step\n",
      "Hybrid FastText-LSTM Model → Accuracy: 0.9149, Precision: 0.9332, Recall: 0.8937, F1-Score: 0.9130\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "model.fit(X_padded, y, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = (model.predict(X_padded) > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "\n",
    "print(f\"Hybrid FastText-LSTM Model → Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:31:59.580304Z",
     "iopub.status.busy": "2025-02-09T20:31:59.579853Z",
     "iopub.status.idle": "2025-02-09T20:31:59.719731Z",
     "shell.execute_reply": "2025-02-09T20:31:59.718252Z",
     "shell.execute_reply.started": "2025-02-09T20:31:59.580269Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=300, weights=[embedding_matrix], input_length=max_len, trainable=True),\n",
    "    LSTM(64, return_sequences=False, dropout=0.2, recurrent_dropout=0.2),\n",
    "    #LSTM(32, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:32:03.080638Z",
     "iopub.status.busy": "2025-02-09T20:32:03.080274Z",
     "iopub.status.idle": "2025-02-09T20:57:16.582695Z",
     "shell.execute_reply": "2025-02-09T20:57:16.581237Z",
     "shell.execute_reply.started": "2025-02-09T20:32:03.080610Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 216ms/step - accuracy: 0.7934 - loss: 0.4623 - val_accuracy: 0.8290 - val_loss: 0.3925\n",
      "Epoch 2/5\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 209ms/step - accuracy: 0.8489 - loss: 0.3643 - val_accuracy: 0.8367 - val_loss: 0.3850\n",
      "Epoch 3/5\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 212ms/step - accuracy: 0.8757 - loss: 0.3046 - val_accuracy: 0.8417 - val_loss: 0.3891\n",
      "Epoch 4/5\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 203ms/step - accuracy: 0.9003 - loss: 0.2491 - val_accuracy: 0.8462 - val_loss: 0.4127\n",
      "Epoch 5/5\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 211ms/step - accuracy: 0.9192 - loss: 0.2076 - val_accuracy: 0.8443 - val_loss: 0.4390\n",
      "\u001b[1m3139/3139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 41ms/step\n",
      "Hybrid FastText-LSTM Model → Accuracy: 0.9211, Precision: 0.9235, Recall: 0.9183, F1-Score: 0.9209\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "model.fit(X_padded, y, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = (model.predict(X_padded) > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "\n",
    "print(f\"Hybrid FastText-LSTM Model → Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6137934,
     "sourceId": 9975800,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
