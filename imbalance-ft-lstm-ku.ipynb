{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-17T16:59:04.822621Z",
     "iopub.status.busy": "2025-02-17T16:59:04.822173Z",
     "iopub.status.idle": "2025-02-17T16:59:23.273544Z",
     "shell.execute_reply": "2025-02-17T16:59:23.272208Z",
     "shell.execute_reply.started": "2025-02-17T16:59:04.822572Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T16:59:23.275813Z",
     "iopub.status.busy": "2025-02-17T16:59:23.275037Z",
     "iopub.status.idle": "2025-02-17T16:59:23.432094Z",
     "shell.execute_reply": "2025-02-17T16:59:23.430896Z",
     "shell.execute_reply.started": "2025-02-17T16:59:23.275765Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T16:59:23.434621Z",
     "iopub.status.busy": "2025-02-17T16:59:23.434199Z",
     "iopub.status.idle": "2025-02-17T16:59:40.938002Z",
     "shell.execute_reply": "2025-02-17T16:59:40.936772Z",
     "shell.execute_reply.started": "2025-02-17T16:59:23.434588Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dsk = pd.read_excel('/kaggle/input/kurdishkdfnd/KDFND_Anlyzed_Cleaned_Filtered_Labeld.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T16:59:40.939909Z",
     "iopub.status.busy": "2025-02-17T16:59:40.939172Z",
     "iopub.status.idle": "2025-02-17T16:59:41.055332Z",
     "shell.execute_reply": "2025-02-17T16:59:41.054098Z",
     "shell.execute_reply.started": "2025-02-17T16:59:40.939870Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dsk = dsk.dropna(subset=['Text'])\n",
    "dsk[\"Article\"] = dsk[\"Text\"]\n",
    "dsk['label'] = dsk['label'].map({'Real': 0, 'Fake': 1})  # Convert labels to 0 and 1\n",
    "dsk = dsk[['Article', 'label']].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T16:59:41.056716Z",
     "iopub.status.busy": "2025-02-17T16:59:41.056368Z",
     "iopub.status.idle": "2025-02-17T16:59:41.079349Z",
     "shell.execute_reply": "2025-02-17T16:59:41.077937Z",
     "shell.execute_reply.started": "2025-02-17T16:59:41.056677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "# Assuming 'dsk' is your DataFrame and you have a binary label column called 'label'\n",
    "# Split the dataset into majority and minority classes\n",
    "majority_class = dsk[dsk['label'] == 0]\n",
    "minority_class = dsk[dsk['label'] == 1]\n",
    "\n",
    "# Perform oversampling on the minority class # Sample with replacement  # Match majority size\n",
    "###minority_oversampled = resample(minority_class,replace=True, n_samples=len(majority_class), random_state=42)  # For reproducibility\n",
    "# Perform undersampling on the minority class\n",
    "majority_undersampled = resample(majority_class,replace=True, n_samples=len(minority_class), random_state=42)  # For reproducibility\n",
    "\n",
    "# Combine majority class with the oversampled minority class\n",
    "###dskb = pd.concat([majority_class, minority_oversampled])\n",
    "# Combine majority class with the undersampled minority class\n",
    "#dskb = pd.concat([minority_class, majority_undersampled])\n",
    "\n",
    "# Shuffle the dataset\n",
    "#dskb = dskb.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#print(\"Balanced class distribution:\")\n",
    "#print(dskb['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T17:01:15.070526Z",
     "iopub.status.busy": "2025-02-17T17:01:15.070038Z",
     "iopub.status.idle": "2025-02-17T17:01:19.140498Z",
     "shell.execute_reply": "2025-02-17T17:01:19.139403Z",
     "shell.execute_reply.started": "2025-02-17T17:01:15.070490Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ئەرشیف هاونیشتمانی بەیەکەوە پاسپۆرتەکانی عێراق...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>هێشتا هەرجوانە دڵێکی بۆدانێن</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>نەخۆشخانەی ڕانییە قەرەبالغیەکی یەکجار زۆر هەی،...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ئێستا ڕانیە</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>هاوڕی باشەکان گرنگی یەکتر دەدەن هاوڕێ نزیکەکان...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100957</th>\n",
       "      <td>کەرکووک؛ پیاوێکی 52 ساڵ گوشاری هاوژینەکەیدا ما...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100958</th>\n",
       "      <td>تەقینەوەیەک ناوچەی سەوزی بەغدا ڕوویدا</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100959</th>\n",
       "      <td>باسیان لەچی کرد؟ زانیاری ورد بخوێنەوە پاپاوە س...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100960</th>\n",
       "      <td>ئێران گیانلەدەستدانی خۆپیشاندەرێکی ڕاگەیاند</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100961</th>\n",
       "      <td>فڕۆکەکانی تورکیا شنگالیان بۆردومانکرد</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Article  label\n",
       "0       ئەرشیف هاونیشتمانی بەیەکەوە پاسپۆرتەکانی عێراق...      1\n",
       "1                            هێشتا هەرجوانە دڵێکی بۆدانێن      1\n",
       "2       نەخۆشخانەی ڕانییە قەرەبالغیەکی یەکجار زۆر هەی،...      1\n",
       "3                                             ئێستا ڕانیە      1\n",
       "4       هاوڕی باشەکان گرنگی یەکتر دەدەن هاوڕێ نزیکەکان...      1\n",
       "...                                                   ...    ...\n",
       "100957  کەرکووک؛ پیاوێکی 52 ساڵ گوشاری هاوژینەکەیدا ما...      0\n",
       "100958              تەقینەوەیەک ناوچەی سەوزی بەغدا ڕوویدا      0\n",
       "100959  باسیان لەچی کرد؟ زانیاری ورد بخوێنەوە پاپاوە س...      0\n",
       "100960        ئێران گیانلەدەستدانی خۆپیشاندەرێکی ڕاگەیاند      0\n",
       "100961              فڕۆکەکانی تورکیا شنگالیان بۆردومانکرد      0\n",
       "\n",
       "[100962 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize and count word frequencies\n",
    "all_words = ' '.join(dsk).split()\n",
    "word_freq = Counter(all_words)\n",
    "\n",
    "# Identify potential stopwords (e.g., words appearing very frequently)\n",
    "potential_stopwords = [word for word, freq in word_freq.items() if freq > 1]\n",
    "\n",
    "# Example stopwords list (refined manually)\n",
    "kurdish_stopwords = [\n",
    "     \"ئێمە\",\"ئێوە\",\"ئەم\",\"ئەو\"\n",
    "     ,\"ئەوان\",\"ئەوەی\",\"بۆ\",\"بێ\",\"بێجگە\",\"بە\",\"بەبێ\",\"بەدەم\",\"بەردەم\",\"بەرلە\",\"بەرەوی\",\"بەرەوە\",\"بەلای\",\"بەپێی\",\"تۆ\",\"تێ\",\"جگە\",\"دوای\",\"دوو\",\"دە\"\n",
    "     ,\"دەکات\",\"دەگەڵ\",\"سەر\",\"لێ\",\"لە\",\"لەبابەت\",\"لەباتی\",\"لەبارەی\",\"لەبرێتی\",\"لەبن\",\"لەبەر\",\"لەبەینی\",\"لەدەم\",\"لەرێ\",\"لەرێگا\",\"لەرەوی\",\"لەسەر\",\"لەلایەن\"\n",
    "     ,\"لەناو\",\"لەنێو\",\"لەو\",\"لەپێناوی\",\"لەژێر\",\"لەگەڵ\",\"من\",\"ناو\",\"نێوان\",\"هەر\",\"هەروەها\",\"و\",\"وەک\",\"پاش\",\"پێ\",\"پێش\",\"چەند\",\"کرد\",\"کە\",\"ی\"\n",
    "\n",
    "] + potential_stopwords\n",
    "\n",
    "kupunctuation = {'!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?',\n",
    "                 '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~'}\n",
    "\n",
    "# Convert set to list before concatenation\n",
    "ku_stopwords = kurdish_stopwords + list(kupunctuation)\n",
    "\n",
    "def rremove_stopwords(text, stop_words):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "    \n",
    "# Apply the function to each article\n",
    "dsk['Article'] = dsk['Article'].apply(lambda text: rremove_stopwords(text, ku_stopwords))\n",
    "dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T17:01:20.402215Z",
     "iopub.status.busy": "2025-02-17T17:01:20.401716Z",
     "iopub.status.idle": "2025-02-17T17:01:25.016998Z",
     "shell.execute_reply": "2025-02-17T17:01:25.015285Z",
     "shell.execute_reply.started": "2025-02-17T17:01:20.402163Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ئەرشیف هاونیشتمانی بەیەکەوە پاسپۆرتەکانی عێراق...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>هێشتا هەرجوانە دڵێکی بۆدانێن</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>نەخۆشخانەی ڕانییە قەرەبالغیەکی یەکجار زۆر هەیب...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ئێستا ڕانیە</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>هاوڕی باشەکان گرنگی یەکتر دەدەن هاوڕێ نزیکەکان...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100957</th>\n",
       "      <td>کەرکووک پیاوێکی  ساڵ گوشاری هاوژینەکەیدا ماڵ د...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100958</th>\n",
       "      <td>تەقینەوەیەک ناوچەی سەوزی بەغدا ڕوویدا</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100959</th>\n",
       "      <td>باسیان لەچی کرد زانیاری ورد بخوێنەوە پاپاوە سە...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100960</th>\n",
       "      <td>ئێران گیانلەدەستدانی خۆپیشاندەرێکی ڕاگەیاند</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100961</th>\n",
       "      <td>فڕۆکەکانی تورکیا شنگالیان بۆردومانکرد</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Article  label\n",
       "0       ئەرشیف هاونیشتمانی بەیەکەوە پاسپۆرتەکانی عێراق...      1\n",
       "1                            هێشتا هەرجوانە دڵێکی بۆدانێن      1\n",
       "2       نەخۆشخانەی ڕانییە قەرەبالغیەکی یەکجار زۆر هەیب...      1\n",
       "3                                             ئێستا ڕانیە      1\n",
       "4       هاوڕی باشەکان گرنگی یەکتر دەدەن هاوڕێ نزیکەکان...      1\n",
       "...                                                   ...    ...\n",
       "100957  کەرکووک پیاوێکی  ساڵ گوشاری هاوژینەکەیدا ماڵ د...      0\n",
       "100958              تەقینەوەیەک ناوچەی سەوزی بەغدا ڕوویدا      0\n",
       "100959  باسیان لەچی کرد زانیاری ورد بخوێنەوە پاپاوە سە...      0\n",
       "100960        ئێران گیانلەدەستدانی خۆپیشاندەرێکی ڕاگەیاند      0\n",
       "100961              فڕۆکەکانی تورکیا شنگالیان بۆردومانکرد      0\n",
       "\n",
       "[100962 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wordpre(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"  # Return empty string for non-string inputs\n",
    "    # Remove URLs, special characters, and numbers\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\d+', '', text)      # Remove numbers\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = text.strip()\n",
    "   \n",
    "    return text\n",
    "\n",
    "##  Applying the wordpre method to the dataset\n",
    "dsk['Article']=dsk['Article'].apply(wordpre)\n",
    "dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T17:01:25.019470Z",
     "iopub.status.busy": "2025-02-17T17:01:25.018995Z",
     "iopub.status.idle": "2025-02-17T17:01:25.089530Z",
     "shell.execute_reply": "2025-02-17T17:01:25.088176Z",
     "shell.execute_reply.started": "2025-02-17T17:01:25.019431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dsk['label1'] = \"__label__\" + dsk['label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T17:01:25.983060Z",
     "iopub.status.busy": "2025-02-17T17:01:25.982550Z",
     "iopub.status.idle": "2025-02-17T17:01:26.063504Z",
     "shell.execute_reply": "2025-02-17T17:01:26.062425Z",
     "shell.execute_reply.started": "2025-02-17T17:01:25.983016Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>label</th>\n",
       "      <th>label1</th>\n",
       "      <th>label_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ئەرشیف هاونیشتمانی بەیەکەوە پاسپۆرتەکانی عێراق...</td>\n",
       "      <td>1</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 ئەرشیف هاونیشتمانی بەیەکەوە پاسپۆرت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>هێشتا هەرجوانە دڵێکی بۆدانێن</td>\n",
       "      <td>1</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 هێشتا هەرجوانە دڵێکی بۆدانێن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>نەخۆشخانەی ڕانییە قەرەبالغیەکی یەکجار زۆر هەیب...</td>\n",
       "      <td>1</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 نەخۆشخانەی ڕانییە قەرەبالغیەکی یەکج...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ئێستا ڕانیە</td>\n",
       "      <td>1</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 ئێستا ڕانیە</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>هاوڕی باشەکان گرنگی یەکتر دەدەن هاوڕێ نزیکەکان...</td>\n",
       "      <td>1</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 هاوڕی باشەکان گرنگی یەکتر دەدەن هاو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100957</th>\n",
       "      <td>کەرکووک پیاوێکی  ساڵ گوشاری هاوژینەکەیدا ماڵ د...</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__0</td>\n",
       "      <td>__label__0 کەرکووک پیاوێکی  ساڵ گوشاری هاوژینە...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100958</th>\n",
       "      <td>تەقینەوەیەک ناوچەی سەوزی بەغدا ڕوویدا</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__0</td>\n",
       "      <td>__label__0 تەقینەوەیەک ناوچەی سەوزی بەغدا ڕوویدا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100959</th>\n",
       "      <td>باسیان لەچی کرد زانیاری ورد بخوێنەوە پاپاوە سە...</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__0</td>\n",
       "      <td>__label__0 باسیان لەچی کرد زانیاری ورد بخوێنەو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100960</th>\n",
       "      <td>ئێران گیانلەدەستدانی خۆپیشاندەرێکی ڕاگەیاند</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__0</td>\n",
       "      <td>__label__0 ئێران گیانلەدەستدانی خۆپیشاندەرێکی ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100961</th>\n",
       "      <td>فڕۆکەکانی تورکیا شنگالیان بۆردومانکرد</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__0</td>\n",
       "      <td>__label__0 فڕۆکەکانی تورکیا شنگالیان بۆردومانکرد</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100962 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Article  label      label1  \\\n",
       "0       ئەرشیف هاونیشتمانی بەیەکەوە پاسپۆرتەکانی عێراق...      1  __label__1   \n",
       "1                            هێشتا هەرجوانە دڵێکی بۆدانێن      1  __label__1   \n",
       "2       نەخۆشخانەی ڕانییە قەرەبالغیەکی یەکجار زۆر هەیب...      1  __label__1   \n",
       "3                                             ئێستا ڕانیە      1  __label__1   \n",
       "4       هاوڕی باشەکان گرنگی یەکتر دەدەن هاوڕێ نزیکەکان...      1  __label__1   \n",
       "...                                                   ...    ...         ...   \n",
       "100957  کەرکووک پیاوێکی  ساڵ گوشاری هاوژینەکەیدا ماڵ د...      0  __label__0   \n",
       "100958              تەقینەوەیەک ناوچەی سەوزی بەغدا ڕوویدا      0  __label__0   \n",
       "100959  باسیان لەچی کرد زانیاری ورد بخوێنەوە پاپاوە سە...      0  __label__0   \n",
       "100960        ئێران گیانلەدەستدانی خۆپیشاندەرێکی ڕاگەیاند      0  __label__0   \n",
       "100961              فڕۆکەکانی تورکیا شنگالیان بۆردومانکرد      0  __label__0   \n",
       "\n",
       "                                        label_description  \n",
       "0       __label__1 ئەرشیف هاونیشتمانی بەیەکەوە پاسپۆرت...  \n",
       "1                 __label__1 هێشتا هەرجوانە دڵێکی بۆدانێن  \n",
       "2       __label__1 نەخۆشخانەی ڕانییە قەرەبالغیەکی یەکج...  \n",
       "3                                  __label__1 ئێستا ڕانیە  \n",
       "4       __label__1 هاوڕی باشەکان گرنگی یەکتر دەدەن هاو...  \n",
       "...                                                   ...  \n",
       "100957  __label__0 کەرکووک پیاوێکی  ساڵ گوشاری هاوژینە...  \n",
       "100958   __label__0 تەقینەوەیەک ناوچەی سەوزی بەغدا ڕوویدا  \n",
       "100959  __label__0 باسیان لەچی کرد زانیاری ورد بخوێنەو...  \n",
       "100960  __label__0 ئێران گیانلەدەستدانی خۆپیشاندەرێکی ...  \n",
       "100961   __label__0 فڕۆکەکانی تورکیا شنگالیان بۆردومانکرد  \n",
       "\n",
       "[100962 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsk['label_description'] = dsk['label1'].astype(str) + \" \" + dsk['Article'].astype(str)\n",
    "dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T17:01:31.271200Z",
     "iopub.status.busy": "2025-02-17T17:01:31.270766Z",
     "iopub.status.idle": "2025-02-17T17:01:31.316510Z",
     "shell.execute_reply": "2025-02-17T17:01:31.315096Z",
     "shell.execute_reply.started": "2025-02-17T17:01:31.271162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(dsk, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T17:01:32.937791Z",
     "iopub.status.busy": "2025-02-17T17:01:32.937409Z",
     "iopub.status.idle": "2025-02-17T17:01:33.643322Z",
     "shell.execute_reply": "2025-02-17T17:01:33.641887Z",
     "shell.execute_reply.started": "2025-02-17T17:01:32.937761Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"fake_news_train.txt\", columns = ['label_description'], index=False, sep=' ', header=False,\n",
    "    quoting=3, escapechar=' ', mode='w')\n",
    "test.to_csv(\"fake_news_test.txt\", columns = ['label_description'], index=False, sep=' ', header=False,\n",
    "    quoting=3, escapechar=' ', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T17:01:35.149193Z",
     "iopub.status.busy": "2025-02-17T17:01:35.148795Z",
     "iopub.status.idle": "2025-02-17T17:02:24.642475Z",
     "shell.execute_reply": "2025-02-17T17:02:24.641460Z",
     "shell.execute_reply.started": "2025-02-17T17:01:35.149116Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train FastText Model\n",
    "fasttext_model = fasttext.train_supervised(input=\"fake_news_train.txt\", lr=0.5, epoch=25, wordNgrams=2, dim=300)\n",
    "y_predic = fasttext_model.test(\"fake_news_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T17:02:24.643990Z",
     "iopub.status.busy": "2025-02-17T17:02:24.643669Z",
     "iopub.status.idle": "2025-02-17T17:02:24.652581Z",
     "shell.execute_reply": "2025-02-17T17:02:24.651477Z",
     "shell.execute_reply.started": "2025-02-17T17:02:24.643962Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Test: 20193\n",
      "Precision: 0.802060\n",
      "Recall: 0.802060\n",
      "F1-Score: 0.802060\n"
     ]
    }
   ],
   "source": [
    "N = y_predic[0]\n",
    "P = y_predic[1]\n",
    "R = y_predic[2]\n",
    "\n",
    "print(f\"No. of Test: {N:}\")\n",
    "print(f\"Precision: {P:.6f}\")\n",
    "print(f\"Recall: {R:.6f}\")\n",
    "\n",
    "print(f\"F1-Score: {2*((P*R)/(P+R)):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T17:02:24.654879Z",
     "iopub.status.busy": "2025-02-17T17:02:24.654488Z",
     "iopub.status.idle": "2025-02-17T17:02:29.689468Z",
     "shell.execute_reply": "2025-02-17T17:02:29.688294Z",
     "shell.execute_reply.started": "2025-02-17T17:02:24.654848Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to get FastText vector safely\n",
    "def fasttext_vector(text):\n",
    "    if isinstance(text, str):  # Ensure text is a string\n",
    "        text = text.replace(\"\\n\", \" \").strip()  # Remove newlines\n",
    "        return fasttext_model.get_sentence_vector(text)\n",
    "    return np.zeros(300)  # Return zero vector for empty/non-string values\n",
    "\n",
    "# Apply FastText vectors to dataset\n",
    "X_fasttext = np.array([fasttext_vector(text) for text in dsk['Article']])\n",
    "# Function to get FastText vector\n",
    "y = np.array(dsk['label'])\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fasttext, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T17:02:29.691016Z",
     "iopub.status.busy": "2025-02-17T17:02:29.690646Z",
     "iopub.status.idle": "2025-02-17T17:02:39.514042Z",
     "shell.execute_reply": "2025-02-17T17:02:39.512956Z",
     "shell.execute_reply.started": "2025-02-17T17:02:29.690975Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "max_words = 10000\n",
    "max_len = 200\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(dsk['Article'])\n",
    "X_sequences = tokenizer.texts_to_sequences(dsk['Article'])\n",
    "X_padded = pad_sequences(X_sequences, maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T17:02:39.515358Z",
     "iopub.status.busy": "2025-02-17T17:02:39.515047Z",
     "iopub.status.idle": "2025-02-17T17:02:39.662517Z",
     "shell.execute_reply": "2025-02-17T17:02:39.661443Z",
     "shell.execute_reply.started": "2025-02-17T17:02:39.515332Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Embedding Matrix from FastText\n",
    "embedding_matrix = np.zeros((max_words, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_matrix[i] = fasttext_model.get_word_vector(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T19:52:45.177239Z",
     "iopub.status.busy": "2025-02-04T19:52:45.176936Z",
     "iopub.status.idle": "2025-02-04T19:52:45.319622Z",
     "shell.execute_reply": "2025-02-04T19:52:45.318375Z",
     "shell.execute_reply.started": "2025-02-04T19:52:45.177215Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=300, weights=[embedding_matrix], input_length=max_len, trainable=True),\n",
    "    Bidirectional(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    LSTM(32, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T19:52:53.537760Z",
     "iopub.status.busy": "2025-02-04T19:52:53.537296Z",
     "iopub.status.idle": "2025-02-04T20:43:01.219254Z",
     "shell.execute_reply": "2025-02-04T20:43:01.217991Z",
     "shell.execute_reply.started": "2025-02-04T19:52:53.537722Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 442ms/step - accuracy: 0.8185 - loss: 0.4216 - val_accuracy: 0.7963 - val_loss: 0.4648\n",
      "Epoch 2/5\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 437ms/step - accuracy: 0.8633 - loss: 0.3301 - val_accuracy: 0.7674 - val_loss: 0.5823\n",
      "Epoch 3/5\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 435ms/step - accuracy: 0.8826 - loss: 0.2842 - val_accuracy: 0.7761 - val_loss: 0.5189\n",
      "Epoch 4/5\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 434ms/step - accuracy: 0.9023 - loss: 0.2376 - val_accuracy: 0.7787 - val_loss: 0.5993\n",
      "Epoch 5/5\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 430ms/step - accuracy: 0.9220 - loss: 0.1936 - val_accuracy: 0.7821 - val_loss: 0.6207\n",
      "\u001b[1m3156/3156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 79ms/step\n",
      "Hybrid FastText-LSTM Model → Accuracy: 0.9092, Precision: 0.8810, Recall: 0.9450, F1-Score: 0.9119\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "model.fit(X_padded, y, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = (model.predict(X_padded) > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "\n",
    "print(f\"Hybrid FastText-LSTM Model → Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T17:02:59.746847Z",
     "iopub.status.busy": "2025-02-17T17:02:59.746364Z",
     "iopub.status.idle": "2025-02-17T17:02:59.885209Z",
     "shell.execute_reply": "2025-02-17T17:02:59.883777Z",
     "shell.execute_reply.started": "2025-02-17T17:02:59.746814Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=300, weights=[embedding_matrix], input_length=max_len, trainable=True),\n",
    "    LSTM(64, return_sequences=False, dropout=0.2, recurrent_dropout=0.2),\n",
    "    #LSTM(32, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-17T17:03:06.438828Z",
     "iopub.status.busy": "2025-02-17T17:03:06.438385Z",
     "iopub.status.idle": "2025-02-17T17:26:20.300478Z",
     "shell.execute_reply": "2025-02-17T17:26:20.299120Z",
     "shell.execute_reply.started": "2025-02-17T17:03:06.438796Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 204ms/step - accuracy: 0.8167 - loss: 0.4154 - val_accuracy: 0.7673 - val_loss: 0.5132\n",
      "Epoch 2/5\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 202ms/step - accuracy: 0.8670 - loss: 0.3202 - val_accuracy: 0.7961 - val_loss: 0.4622\n",
      "Epoch 3/5\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 200ms/step - accuracy: 0.8876 - loss: 0.2699 - val_accuracy: 0.7931 - val_loss: 0.5399\n",
      "Epoch 4/5\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 199ms/step - accuracy: 0.9055 - loss: 0.2249 - val_accuracy: 0.7280 - val_loss: 0.7752\n",
      "Epoch 5/5\n",
      "\u001b[1m1263/1263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 201ms/step - accuracy: 0.9260 - loss: 0.1780 - val_accuracy: 0.7808 - val_loss: 0.7903\n",
      "\u001b[1m3156/3156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 38ms/step\n",
      "Hybrid FastText-LSTM Model → Accuracy: 0.9142, Precision: 0.8868, Recall: 0.9485, F1-Score: 0.9166\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "model.fit(X_padded, y, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = (model.predict(X_padded) > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "\n",
    "print(f\"Hybrid FastText-LSTM Model → Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6135721,
     "sourceId": 9972841,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6137934,
     "sourceId": 9975800,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
