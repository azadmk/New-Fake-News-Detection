{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-09T20:25:13.050357Z",
     "iopub.status.busy": "2025-02-09T20:25:13.050037Z",
     "iopub.status.idle": "2025-02-09T20:25:24.837976Z",
     "shell.execute_reply": "2025-02-09T20:25:24.836973Z",
     "shell.execute_reply.started": "2025-02-09T20:25:13.050328Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, SimpleRNN, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, MaxPooling1D, SimpleRNN, Dense, Dropout, GlobalMaxPooling1D, Bidirectional\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import BatchNormalization,SpatialDropout1D\n",
    "from keras.optimizers import RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:25:24.840016Z",
     "iopub.status.busy": "2025-02-09T20:25:24.839397Z",
     "iopub.status.idle": "2025-02-09T20:25:25.125115Z",
     "shell.execute_reply": "2025-02-09T20:25:25.124272Z",
     "shell.execute_reply.started": "2025-02-09T20:25:24.839985Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Downloading nltk StopWords and Wordnet \n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:25:25.127380Z",
     "iopub.status.busy": "2025-02-09T20:25:25.127015Z",
     "iopub.status.idle": "2025-02-09T20:25:41.386717Z",
     "shell.execute_reply": "2025-02-09T20:25:41.385689Z",
     "shell.execute_reply.started": "2025-02-09T20:25:25.127352Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dsk = pd.read_excel('/kaggle/input/kurdishenglish/KDFND_Anlyzed_Cleaned_Filtered_Labeld.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:25:41.482248Z",
     "iopub.status.busy": "2025-02-09T20:25:41.481958Z",
     "iopub.status.idle": "2025-02-09T20:25:41.594949Z",
     "shell.execute_reply": "2025-02-09T20:25:41.593863Z",
     "shell.execute_reply.started": "2025-02-09T20:25:41.482223Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Remove null Rows\n",
    "dsk = dsk.dropna(subset=['Text_Translate_to_English'])\n",
    "dsk = dsk.dropna(subset=['Text'])\n",
    "\n",
    "# Remove columns that not needed\n",
    "dsk[\"Article\"] = dsk[\"Text_Translate_to_English\"]\n",
    "dsk['label'] = dsk['label'].map({'Real': 0, 'Fake': 1})  # Convert labels to 0 and 1\n",
    "dsk = dsk[['Article', 'label']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:25:41.596359Z",
     "iopub.status.busy": "2025-02-09T20:25:41.595990Z",
     "iopub.status.idle": "2025-02-09T20:25:41.617310Z",
     "shell.execute_reply": "2025-02-09T20:25:41.616378Z",
     "shell.execute_reply.started": "2025-02-09T20:25:41.596319Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Article    0\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsk.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:25:41.618587Z",
     "iopub.status.busy": "2025-02-09T20:25:41.618304Z",
     "iopub.status.idle": "2025-02-09T20:25:41.797533Z",
     "shell.execute_reply": "2025-02-09T20:25:41.796447Z",
     "shell.execute_reply.started": "2025-02-09T20:25:41.618564Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for null/empty rows\n",
    "print(dsk['Article'].isna().sum())  # Count NaN entries\n",
    "print((dsk['Article'].str.strip() == '').sum())  # Count empty strings\n",
    "\n",
    "# Remove rows where 'Article' is an empty string after stripping whitespace\n",
    "dsk = dsk[dsk['Article'].str.strip() != '']\n",
    "\n",
    "# Check for null/empty rows\n",
    "print(dsk['Article'].isna().sum())  # Count NaN entries\n",
    "print((dsk['Article'].str.strip() == '').sum())  # Count empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:25:41.800811Z",
     "iopub.status.busy": "2025-02-09T20:25:41.800533Z",
     "iopub.status.idle": "2025-02-09T20:25:41.831522Z",
     "shell.execute_reply": "2025-02-09T20:25:41.830443Z",
     "shell.execute_reply.started": "2025-02-09T20:25:41.800786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Assuming dsk is your DataFrame\n",
    "# Separate the majority and minority classes\n",
    "df_majority = dsk[dsk['label'] == 0]\n",
    "df_minority = dsk[dsk['label'] == 1]\n",
    "\n",
    "# Oversample the minority class\n",
    "#df_minority_oversampled = df_minority.sample(len(df_majority), replace=True, random_state=2020)\n",
    "df_majority_undersampled = df_majority.sample(len(df_minority), replace=True, random_state=2020)\n",
    "\n",
    "# Combine the majority class with the oversampled minority class\n",
    "#dsk_balanced = pd.concat([df_majority, df_minority_oversampled])\n",
    "dsk_balanced = pd.concat([df_minority, df_majority_undersampled])\n",
    "\n",
    "# Shuffle the dataset\n",
    "#dskb = dsk_balanced.sample(frac=1, random_state=2020).reset_index(drop=True)\n",
    "\n",
    "# Check the new class distribution\n",
    "#grouped_by_class_balanced = dskb.groupby('label').count()\n",
    "#print(grouped_by_class_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:25:41.833348Z",
     "iopub.status.busy": "2025-02-09T20:25:41.833044Z",
     "iopub.status.idle": "2025-02-09T20:25:41.925884Z",
     "shell.execute_reply": "2025-02-09T20:25:41.924749Z",
     "shell.execute_reply.started": "2025-02-09T20:25:41.833322Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.994670055762448, 1: 1.0053873730332603}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "dskb=dsk\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(dskb['label']), y=dskb['label'])\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "print(\"Class weights:\", class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:25:41.927128Z",
     "iopub.status.busy": "2025-02-09T20:25:41.926858Z",
     "iopub.status.idle": "2025-02-09T20:25:43.441393Z",
     "shell.execute_reply": "2025-02-09T20:25:43.440494Z",
     "shell.execute_reply.started": "2025-02-09T20:25:41.927103Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def wordpre(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"  # Return empty string for non-string inputs\n",
    "    text = text.lower()\n",
    "    # Remove URLs, special characters, and numbers\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)      # Remove numbers\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "    \n",
    "##  Applying the wordpre method to the dataset\n",
    "dskb['Article']=dskb['Article'].apply(wordpre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:25:43.442783Z",
     "iopub.status.busy": "2025-02-09T20:25:43.442304Z",
     "iopub.status.idle": "2025-02-09T20:25:44.073044Z",
     "shell.execute_reply": "2025-02-09T20:25:44.072130Z",
     "shell.execute_reply.started": "2025-02-09T20:25:43.442742Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>archive citizens burn iraqi passports together...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>still beautiful put heart</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ranya hospital crowded according information f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ranya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good friends care close friends understand tru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article label\n",
       "0  archive citizens burn iraqi passports together...     1\n",
       "1                          still beautiful put heart     1\n",
       "2  ranya hospital crowded according information f...     1\n",
       "3                                              ranya     1\n",
       "4  good friends care close friends understand tru...     1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = list(string.punctuation)\n",
    "\n",
    "stop_words.update(punctuation)\n",
    "\n",
    "# Apply the function to each article\n",
    "dskb['Article'] = dskb['Article'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_words ) )\n",
    "\n",
    "dskb.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:25:44.074193Z",
     "iopub.status.busy": "2025-02-09T20:25:44.073909Z",
     "iopub.status.idle": "2025-02-09T20:25:46.197203Z",
     "shell.execute_reply": "2025-02-09T20:25:46.195932Z",
     "shell.execute_reply.started": "2025-02-09T20:25:44.074138Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 41194\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tokenize text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(dskb['Article'])\n",
    "word_index = tokenizer.word_index\n",
    "print(f\"Vocabulary size: {len(word_index)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:25:46.198627Z",
     "iopub.status.busy": "2025-02-09T20:25:46.198245Z",
     "iopub.status.idle": "2025-02-09T20:25:46.202793Z",
     "shell.execute_reply": "2025-02-09T20:25:46.201654Z",
     "shell.execute_reply.started": "2025-02-09T20:25:46.198594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "glove_twitter = \"/kaggle/input/glove-twitter/glove.twitter.27B.200d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:25:46.204193Z",
     "iopub.status.busy": "2025-02-09T20:25:46.203824Z",
     "iopub.status.idle": "2025-02-09T20:26:49.559373Z",
     "shell.execute_reply": "2025-02-09T20:26:49.558203Z",
     "shell.execute_reply.started": "2025-02-09T20:25:46.204131Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe vectors\n",
    "embedding_index = {}\n",
    "with open(glove_twitter, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vectors = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = vectors\n",
    "\n",
    "print(f\"Loaded {len(embedding_index)} word vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:26:49.560578Z",
     "iopub.status.busy": "2025-02-09T20:26:49.560298Z",
     "iopub.status.idle": "2025-02-09T20:26:49.686050Z",
     "shell.execute_reply": "2025-02-09T20:26:49.684978Z",
     "shell.execute_reply.started": "2025-02-09T20:26:49.560543Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (41195, 200)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create embedding matrix\n",
    "embedding_dim = 200\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(\"Embedding matrix shape:\", embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:26:49.687579Z",
     "iopub.status.busy": "2025-02-09T20:26:49.687197Z",
     "iopub.status.idle": "2025-02-09T20:26:49.854902Z",
     "shell.execute_reply": "2025-02-09T20:26:49.854004Z",
     "shell.execute_reply.started": "2025-02-09T20:26:49.687534Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized GloVe Embeddings Shape: (41195, 200)\n",
      "l2_norm: [[8.40894605]\n",
      " [8.32787691]\n",
      " [8.65937445]\n",
      " ...\n",
      " [8.02604343]\n",
      " [8.54577345]\n",
      " [8.47406998]]\n"
     ]
    }
   ],
   "source": [
    "# Example GloVe embedding matrix\n",
    "glove_embedding_matrix = np.random.rand(len(word_index) + 1, 200)  # Random example\n",
    "\n",
    "# L2 normalization of GloVe embeddings\n",
    "l2_norm = np.linalg.norm(glove_embedding_matrix, axis=1, keepdims=True)\n",
    "\n",
    "# Check for zero vectors and handle them\n",
    "# Set zero vectors to a small value to avoid division by zero\n",
    "l2_norm[l2_norm == 0] = 1e-10  # or any small constant\n",
    "\n",
    "# Normalize the embeddings\n",
    "normalized_glove_embeddings = embedding_matrix / l2_norm\n",
    "\n",
    "# Verify the shape of the normalized embeddings\n",
    "print(\"Normalized GloVe Embeddings Shape:\", normalized_glove_embeddings.shape)\n",
    "\n",
    "print(\"l2_norm:\", l2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:26:49.856125Z",
     "iopub.status.busy": "2025-02-09T20:26:49.855876Z",
     "iopub.status.idle": "2025-02-09T20:26:51.983668Z",
     "shell.execute_reply": "2025-02-09T20:26:51.982651Z",
     "shell.execute_reply.started": "2025-02-09T20:26:49.856104Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Pad sequences\n",
    "X = pad_sequences(tokenizer.texts_to_sequences(dskb['Article']), maxlen=100)\n",
    "#X = dskb['Article']\n",
    "y = dskb['label']\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure labels are NumPy arrays and of the correct type\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "y_val = np.array(y_val, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T15:04:17.026081Z",
     "iopub.status.busy": "2025-01-17T15:04:17.025436Z",
     "iopub.status.idle": "2025-01-17T15:04:17.846209Z",
     "shell.execute_reply": "2025-01-17T15:04:17.843962Z",
     "shell.execute_reply.started": "2025-01-17T15:04:17.026037Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">36,860,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_max_pooling1d_6               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │      \u001b[38;5;34m36,860,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_max_pooling1d_6               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,860,000</span> (140.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m36,860,000\u001b[0m (140.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,860,000</span> (140.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36,860,000\u001b[0m (140.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, MaxPooling1D, SimpleRNN, Dense, Dropout, GlobalMaxPooling1D, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import BatchNormalization,SpatialDropout1D\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "#model.add(Input(shape=()))\n",
    "model.add(Embedding(input_dim=len(word_index) + 1,\n",
    "                    output_dim=embedding_dim,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=100, # Pad sequences to this length\n",
    "                    trainable=True)) # Freeze embedding layer\n",
    "model.add(LSTM(70,return_sequences=True, input_shape=(X_train.shape[1], 1)))   # 3D input\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=100, kernel_size=2, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())  # Global Max Pooling\n",
    "model.add(Dense(260, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy', optimizer=RMSprop(learning_rate=1e-3), metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T15:04:22.077320Z",
     "iopub.status.busy": "2025-01-17T15:04:22.076906Z",
     "iopub.status.idle": "2025-01-17T15:57:31.028854Z",
     "shell.execute_reply": "2025-01-17T15:57:31.027569Z",
     "shell.execute_reply.started": "2025-01-17T15:04:22.077283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m644s\u001b[0m 508ms/step - accuracy: 0.7646 - loss: 0.4868 - val_accuracy: 0.8681 - val_loss: 0.3239 - learning_rate: 0.0010\n",
      "Epoch 2/5\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m635s\u001b[0m 506ms/step - accuracy: 0.9199 - loss: 0.2099 - val_accuracy: 0.8749 - val_loss: 0.3111 - learning_rate: 0.0010\n",
      "Epoch 3/5\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m635s\u001b[0m 505ms/step - accuracy: 0.9630 - loss: 0.1021 - val_accuracy: 0.8683 - val_loss: 0.3535 - learning_rate: 0.0010\n",
      "Epoch 4/5\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 505ms/step - accuracy: 0.9792 - loss: 0.0589 - val_accuracy: 0.8712 - val_loss: 0.4609 - learning_rate: 0.0010\n",
      "Epoch 5/5\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 497ms/step - accuracy: 0.9868 - loss: 0.0393 - val_accuracy: 0.8669 - val_loss: 0.5278 - learning_rate: 0.0010\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.8728 - loss: 0.3166\n",
      "Validation Accuracy: 0.8749253153800964\n"
     ]
    }
   ],
   "source": [
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_val, y_val), callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "# Evaluate model\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:27:51.011693Z",
     "iopub.status.busy": "2025-02-09T20:27:51.011260Z",
     "iopub.status.idle": "2025-02-09T20:27:51.319220Z",
     "shell.execute_reply": "2025-02-09T20:27:51.318262Z",
     "shell.execute_reply.started": "2025-02-09T20:27:51.011656Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,239,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │       \u001b[38;5;34m8,239,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,239,000</span> (31.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,239,000\u001b[0m (31.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,239,000</span> (31.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,239,000\u001b[0m (31.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, MaxPooling1D, SimpleRNN, Dense, Dropout, GlobalMaxPooling1D, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import BatchNormalization,SpatialDropout1D\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(word_index) + 1,\n",
    "                    output_dim=embedding_dim,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=100, # Pad sequences to this length\n",
    "                    trainable=False)) # Freeze embedding layer\n",
    "model.add(LSTM(128, return_sequences=False, input_shape=(X_train.shape[1], 1)))  # 3D input\n",
    "model.add(Dropout(0.4))\n",
    "#model.add(Bidirectional(LSTM(70)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy', optimizer=RMSprop(learning_rate=1e-3), metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T20:28:56.238779Z",
     "iopub.status.busy": "2025-02-09T20:28:56.238411Z",
     "iopub.status.idle": "2025-02-09T20:55:30.008130Z",
     "shell.execute_reply": "2025-02-09T20:55:30.006958Z",
     "shell.execute_reply.started": "2025-02-09T20:28:56.238753Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1262/1262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 138ms/step - accuracy: 0.7269 - loss: 0.5480 - val_accuracy: 0.7766 - val_loss: 0.4815 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1262/1262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 137ms/step - accuracy: 0.7818 - loss: 0.4781 - val_accuracy: 0.7880 - val_loss: 0.4608 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1262/1262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 137ms/step - accuracy: 0.7990 - loss: 0.4474 - val_accuracy: 0.7963 - val_loss: 0.4481 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1262/1262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 138ms/step - accuracy: 0.8119 - loss: 0.4222 - val_accuracy: 0.7992 - val_loss: 0.4423 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1262/1262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 137ms/step - accuracy: 0.8145 - loss: 0.4172 - val_accuracy: 0.7981 - val_loss: 0.4429 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m1262/1262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 138ms/step - accuracy: 0.8262 - loss: 0.3964 - val_accuracy: 0.8019 - val_loss: 0.4452 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m1262/1262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 138ms/step - accuracy: 0.8328 - loss: 0.3808 - val_accuracy: 0.8013 - val_loss: 0.4515 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m1262/1262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 138ms/step - accuracy: 0.8515 - loss: 0.3457 - val_accuracy: 0.8025 - val_loss: 0.4553 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1262/1262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 138ms/step - accuracy: 0.8604 - loss: 0.3287 - val_accuracy: 0.8030 - val_loss: 0.4607 - learning_rate: 5.0000e-04\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - accuracy: 0.8017 - loss: 0.4411\n",
      "Validation Accuracy: 0.7991878390312195\n"
     ]
    }
   ],
   "source": [
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_val, y_val), callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "# Evaluate model\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-16T22:10:02.873915Z",
     "iopub.status.busy": "2025-01-16T22:10:02.873490Z",
     "iopub.status.idle": "2025-01-16T22:10:03.012527Z",
     "shell.execute_reply": "2025-01-16T22:10:03.011582Z",
     "shell.execute_reply.started": "2025-01-16T22:10:02.873881Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">7,875,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │       \u001b[38;5;34m7,875,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,875,600</span> (30.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,875,600\u001b[0m (30.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,875,600</span> (30.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,875,600\u001b[0m (30.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, MaxPooling1D, SimpleRNN, Dense, Dropout, GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import BatchNormalization,SpatialDropout1D\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "#model.add(Input(shape=()))\n",
    "model.add(Embedding(input_dim=len(word_index) + 1,\n",
    "                    output_dim=embedding_dim,\n",
    "                    weights=[normalized_glove_embeddings],\n",
    "                    input_length=100, # Pad sequences to this length\n",
    "                    trainable=False)) # Freeze embedding layer\n",
    "model.add(LSTM(128, return_sequences=False, input_shape=(X_train.shape[1], 1)))  # 3D input\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(LSTM(64))\n",
    "model.add(Dropout(0.4)),\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy', optimizer=RMSprop(learning_rate=1e-3), metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T22:10:06.144265Z",
     "iopub.status.busy": "2025-01-16T22:10:06.143897Z",
     "iopub.status.idle": "2025-01-16T22:38:10.980373Z",
     "shell.execute_reply": "2025-01-16T22:38:10.979247Z",
     "shell.execute_reply.started": "2025-01-16T22:10:06.144228Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 129ms/step - accuracy: 0.7925 - loss: 0.4437 - val_accuracy: 0.8825 - val_loss: 0.2635 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 130ms/step - accuracy: 0.8877 - loss: 0.2569 - val_accuracy: 0.8911 - val_loss: 0.2438 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 132ms/step - accuracy: 0.8936 - loss: 0.2412 - val_accuracy: 0.8971 - val_loss: 0.2299 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 132ms/step - accuracy: 0.8969 - loss: 0.2303 - val_accuracy: 0.7825 - val_loss: 0.5020 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 131ms/step - accuracy: 0.7495 - loss: 0.5088 - val_accuracy: 0.8824 - val_loss: 0.2724 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 132ms/step - accuracy: 0.8872 - loss: 0.2627 - val_accuracy: 0.8920 - val_loss: 0.2361 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 132ms/step - accuracy: 0.9029 - loss: 0.2240 - val_accuracy: 0.8965 - val_loss: 0.2358 - learning_rate: 5.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 133ms/step - accuracy: 0.9020 - loss: 0.2204 - val_accuracy: 0.9016 - val_loss: 0.2177 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 135ms/step - accuracy: 0.9099 - loss: 0.2077 - val_accuracy: 0.9019 - val_loss: 0.2156 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 133ms/step - accuracy: 0.9092 - loss: 0.2069 - val_accuracy: 0.9054 - val_loss: 0.2116 - learning_rate: 5.0000e-04\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - accuracy: 0.9072 - loss: 0.2086\n",
      "Validation Accuracy: 0.9054020643234253\n"
     ]
    }
   ],
   "source": [
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_val, y_val), callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "# Evaluate model\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T22:47:55.255840Z",
     "iopub.status.busy": "2025-01-16T22:47:55.255433Z",
     "iopub.status.idle": "2025-01-16T22:47:55.457984Z",
     "shell.execute_reply": "2025-01-16T22:47:55.457037Z",
     "shell.execute_reply.started": "2025-01-16T22:47:55.255804Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">7,875,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">243,688</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,672</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m7,875,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m)                 │         \u001b[38;5;34m243,688\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m2,672\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,121,977</span> (30.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,121,977\u001b[0m (30.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">246,377</span> (962.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m246,377\u001b[0m (962.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,875,600</span> (30.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,875,600\u001b[0m (30.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, MaxPooling1D, SimpleRNN, Dense, Dropout, GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import BatchNormalization,SpatialDropout1D\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "model.add(Embedding(input_dim=len(word_index) + 1,\n",
    "                   output_dim=embedding_dim,weights=[embedding_matrix],input_length=100,trainable=False)) # Freeze embedding layer\n",
    "model.add(LSTM(166, return_sequences=False))\n",
    "model.add(Dropout(0.3)),\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy', optimizer=RMSprop(learning_rate=1e-3), metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T22:48:02.168780Z",
     "iopub.status.busy": "2025-01-16T22:48:02.168270Z",
     "iopub.status.idle": "2025-01-16T23:28:25.481486Z",
     "shell.execute_reply": "2025-01-16T23:28:25.480435Z",
     "shell.execute_reply.started": "2025-01-16T22:48:02.168731Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2511/2511\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 119ms/step - accuracy: 0.8529 - loss: 0.3285 - val_accuracy: 0.8986 - val_loss: 0.2220 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m2511/2511\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 118ms/step - accuracy: 0.9096 - loss: 0.2062 - val_accuracy: 0.9119 - val_loss: 0.2000 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m2511/2511\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 120ms/step - accuracy: 0.9240 - loss: 0.1797 - val_accuracy: 0.9170 - val_loss: 0.1911 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m2511/2511\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 119ms/step - accuracy: 0.9364 - loss: 0.1572 - val_accuracy: 0.9215 - val_loss: 0.1940 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m2511/2511\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 119ms/step - accuracy: 0.9504 - loss: 0.1257 - val_accuracy: 0.9286 - val_loss: 0.1934 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m2511/2511\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 119ms/step - accuracy: 0.9617 - loss: 0.1002 - val_accuracy: 0.9291 - val_loss: 0.1990 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m2511/2511\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 119ms/step - accuracy: 0.9749 - loss: 0.0672 - val_accuracy: 0.9333 - val_loss: 0.2257 - learning_rate: 5.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m2511/2511\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 119ms/step - accuracy: 0.9835 - loss: 0.0473 - val_accuracy: 0.9324 - val_loss: 0.2604 - learning_rate: 5.0000e-04\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 48ms/step - accuracy: 0.9184 - loss: 0.1899\n",
      "Validation Accuracy: 0.9169529676437378\n"
     ]
    }
   ],
   "source": [
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "# Evaluate model\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T23:36:31.919696Z",
     "iopub.status.busy": "2025-01-16T23:36:31.919318Z",
     "iopub.status.idle": "2025-01-16T23:51:31.618091Z",
     "shell.execute_reply": "2025-01-16T23:51:31.616931Z",
     "shell.execute_reply.started": "2025-01-16T23:36:31.919664Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1005/1005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 172ms/step - accuracy: 0.7539 - loss: 0.9195 - val_accuracy: 0.4948 - val_loss: 0.7790\n",
      "Epoch 2/5\n",
      "\u001b[1m1005/1005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 170ms/step - accuracy: 0.8037 - loss: 0.4917 - val_accuracy: 0.8808 - val_loss: 0.3583\n",
      "Epoch 3/5\n",
      "\u001b[1m1005/1005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 171ms/step - accuracy: 0.8481 - loss: 0.4200 - val_accuracy: 0.6084 - val_loss: 0.7134\n",
      "Epoch 4/5\n",
      "\u001b[1m1005/1005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 170ms/step - accuracy: 0.6307 - loss: 0.6837 - val_accuracy: 0.6367 - val_loss: 0.9115\n",
      "Epoch 5/5\n",
      "\u001b[1m1005/1005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 172ms/step - accuracy: 0.6173 - loss: 0.8280 - val_accuracy: 0.7315 - val_loss: 0.6455\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 51ms/step\n",
      "Accuracy: 0.8826487428429176\n",
      "Precision: 0.8664734299516909\n",
      "Recall: 0.9019410640651715\n",
      "F1 Score: 0.883851574434534\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, History\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(dskb['Article'], dskb['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)  # Encode training labels\n",
    "y_test = label_encoder.transform(y_test)  # Encode test labels\n",
    "\n",
    "# Text preprocessing\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(word_index) + 1,\n",
    "                   output_dim=embedding_dim,weights=[embedding_matrix],input_length=max_len,trainable=False))\n",
    "model.add(LSTM(166, dropout=0.4, recurrent_dropout=0.38, kernel_regularizer=l2(0.01)))\n",
    "model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01)))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = History()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_split=0.2, callbacks=[history, early_stopping])\n",
    "\n",
    "# Predict\n",
    "y_pred_prob = model.predict(X_test_pad)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T23:55:57.027628Z",
     "iopub.status.busy": "2025-01-16T23:55:57.027244Z",
     "iopub.status.idle": "2025-01-16T23:55:57.054497Z",
     "shell.execute_reply": "2025-01-16T23:55:57.052846Z",
     "shell.execute_reply.started": "2025-01-16T23:55:57.027597Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 64269\n'y' sizes: 56235\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-94a6249ba1d9>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/data_adapter_utils.py\u001b[0m in \u001b[0;36mcheck_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    112\u001b[0m             )\n\u001b[1;32m    113\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"'{label}' sizes: {sizes}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 64269\n'y' sizes: 56235\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_split=0.2, callbacks=[history, early_stopping])\n",
    "\n",
    "# Evaluate model\n",
    "val_loss, val_accuracy = model.evaluate(X_test_pad, y_test)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T23:51:56.934215Z",
     "iopub.status.busy": "2025-01-16T23:51:56.933863Z",
     "iopub.status.idle": "2025-01-16T23:51:59.545555Z",
     "shell.execute_reply": "2025-01-16T23:51:59.544457Z",
     "shell.execute_reply.started": "2025-01-16T23:51:56.934188Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# Pad sequences\n",
    "X = pad_sequences(tokenizer.texts_to_sequences(dskb['Article']), maxlen=100)\n",
    "y = dskb['label']\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "# Ensure labels are NumPy arrays and of the correct type\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "y_val = np.array(y_val, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T10:55:44.422323Z",
     "iopub.status.busy": "2025-01-11T10:55:44.422057Z",
     "iopub.status.idle": "2025-01-11T11:17:17.183996Z",
     "shell.execute_reply": "2025-01-11T11:17:17.182975Z",
     "shell.execute_reply.started": "2025-01-11T10:55:44.422298Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-11 10:55:46,391] A new study created in memory with name: no-name-d82aa61a-b38d-4a40-9b48-9a07a52ac02b\n",
      "[I 2025-01-11 10:57:52,600] Trial 0 finished with value: 0.706632137298584 and parameters: {'embedding_dim': 100, 'conv_filters': 128, 'kernel_size': 5, 'lstm_units': 253, 'dropout_rate': 0.30567700937688125}. Best is trial 0 with value: 0.706632137298584.\n",
      "[I 2025-01-11 10:59:59,396] Trial 1 finished with value: 0.6993626952171326 and parameters: {'embedding_dim': 50, 'conv_filters': 90, 'kernel_size': 5, 'lstm_units': 176, 'dropout_rate': 0.43471167156770185}. Best is trial 0 with value: 0.706632137298584.\n",
      "[I 2025-01-11 11:02:06,212] Trial 2 finished with value: 0.7129058241844177 and parameters: {'embedding_dim': 100, 'conv_filters': 71, 'kernel_size': 4, 'lstm_units': 168, 'dropout_rate': 0.3085457006568489}. Best is trial 2 with value: 0.7129058241844177.\n",
      "[I 2025-01-11 11:04:13,034] Trial 3 finished with value: 0.7074288129806519 and parameters: {'embedding_dim': 100, 'conv_filters': 125, 'kernel_size': 3, 'lstm_units': 140, 'dropout_rate': 0.1500582900915143}. Best is trial 2 with value: 0.7129058241844177.\n",
      "[I 2025-01-11 11:06:43,548] Trial 4 finished with value: 0.7135530710220337 and parameters: {'embedding_dim': 200, 'conv_filters': 39, 'kernel_size': 4, 'lstm_units': 199, 'dropout_rate': 0.45368274304766243}. Best is trial 4 with value: 0.7135530710220337.\n",
      "[I 2025-01-11 11:08:49,709] Trial 5 finished with value: 0.7102170586585999 and parameters: {'embedding_dim': 100, 'conv_filters': 113, 'kernel_size': 4, 'lstm_units': 58, 'dropout_rate': 0.29242467941146877}. Best is trial 4 with value: 0.7135530710220337.\n",
      "[I 2025-01-11 11:10:56,123] Trial 6 finished with value: 0.7133539319038391 and parameters: {'embedding_dim': 100, 'conv_filters': 110, 'kernel_size': 2, 'lstm_units': 176, 'dropout_rate': 0.3391633835940394}. Best is trial 4 with value: 0.7135530710220337.\n",
      "[I 2025-01-11 11:13:03,278] Trial 7 finished with value: 0.709719181060791 and parameters: {'embedding_dim': 100, 'conv_filters': 63, 'kernel_size': 2, 'lstm_units': 107, 'dropout_rate': 0.22372355636475236}. Best is trial 4 with value: 0.7135530710220337.\n",
      "[I 2025-01-11 11:15:10,491] Trial 8 finished with value: 0.6986157894134521 and parameters: {'embedding_dim': 50, 'conv_filters': 117, 'kernel_size': 2, 'lstm_units': 236, 'dropout_rate': 0.45086491492849}. Best is trial 4 with value: 0.7135530710220337.\n",
      "[I 2025-01-11 11:17:17,176] Trial 9 finished with value: 0.713204562664032 and parameters: {'embedding_dim': 100, 'conv_filters': 112, 'kernel_size': 3, 'lstm_units': 73, 'dropout_rate': 0.2814637399921248}. Best is trial 4 with value: 0.7135530710220337.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'embedding_dim': 200, 'conv_filters': 39, 'kernel_size': 4, 'lstm_units': 199, 'dropout_rate': 0.45368274304766243}\n",
      "Best trial validation accuracy: 0.2864469289779663\n",
      "Best validation accuracy: 0.7135530710220337\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import gc\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Bidirectional, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "#tokenizer = Tokenizer()\n",
    "# Pad sequences\n",
    "X = pad_sequences(tokenizer.texts_to_sequences(dskb['Article']), maxlen=100)\n",
    "y = dskb['label']\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure labels are NumPy arrays and of the correct type\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "y_val = np.array(y_val, dtype=np.float32)\n",
    "\n",
    "embedding_dim = 100  # Fixed dimension matching your embedding matrix\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def create_model(trial):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Hyperparameters to optimize\n",
    "    embedding_dim = trial.suggest_categorical('embedding_dim', [50, 100, 200])\n",
    "    conv_filters = trial.suggest_int('conv_filters', 32, 128)\n",
    "    kernel_size = trial.suggest_int('kernel_size', 2, 5)\n",
    "    lstm_units = trial.suggest_int('lstm_units', 50, 256)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    lstm_units = trial.suggest_int('lstm_units', 50, 256)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    # Dynamically adjust embedding_matrix\n",
    "    adjusted_embedding_matrix = embedding_matrix[:, :embedding_dim]\n",
    "    \n",
    "    \n",
    "    model.add(Embedding(input_dim=len(word_index) + 1,\n",
    "                    output_dim=embedding_dim,\n",
    "                    #weights=[adjusted_embedding_matrix],  # Use the pretrained weights\n",
    "                    trainable=False))  # Trainable embeddings\n",
    "    model.add(LSTM(32, return_sequences=False))\n",
    "    model.add(Dropout(0.3)),\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=3,\n",
    "                        batch_size=64,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        verbose=0)\n",
    "    # Perform garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    # Get the validation accuracy\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    return val_accuracy\n",
    "\n",
    "# Create a study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "# Run Optuna study\n",
    "#study = optuna.create_study(direction=\"minimize\")  # Minimize (1 - accuracy) to maximize accuracy\n",
    "\n",
    "# Best hyperparameters and accuracy\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best trial validation accuracy:\", 1 - study.best_value)\n",
    "# Print validation accuracy of the best trial\n",
    "best_trial = study.best_trial\n",
    "print(\"Best validation accuracy:\", best_trial.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-04T09:56:57.421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import optuna.visualization as vis\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot optimization history (accuracy over trials)\n",
    "optuna.visualization.plot_optimization_history(study)\n",
    "#plt.show()\n",
    "\n",
    "# Plot parameter importances (which hyperparameters affected accuracy most)\n",
    "optuna.visualization.plot_param_importances(study)\n",
    "#plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2357985,
     "sourceId": 3973199,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6137934,
     "sourceId": 9975800,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
